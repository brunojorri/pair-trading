# analysis.py
"""
M√≥dulo de an√°lise para Pairs Trading
Fun√ß√µes estat√≠sticas: cointegra√ß√£o, Z-Score, rolling beta, Kalman Filter, diagn√≥sticos
+ Filtros avan√ßados: ruptura estrutural, estabilidade do beta, volatilidade de mercado
"""

import numpy as np
import pandas as pd
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller
from typing import Tuple, Dict, Any
import warnings

# Suprimir warnings para n√£o poluir o Streamlit
warnings.filterwarnings("ignore")

# Tentar importar yfinance (opcional, mas recomendado)
try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
except ImportError:
    YFINANCE_AVAILABLE = False
    print("‚ö†Ô∏è yfinance n√£o instalado. Filtros de dividendos e IBOV desativados.")


# Cache simples em mem√≥ria
_dividend_cache = {}

def get_next_dividend_date(ticker: str) -> pd.Timestamp:
    """
    Obt√©m a pr√≥xima data de ex-dividendos usando yfinance.
    Usa cache para evitar m√∫ltiplas chamadas.
    Retorna None se n√£o dispon√≠vel.
    """
    if isinstance(ticker, np.ndarray):
        ticker = ticker.item() if ticker.size == 1 else str(ticker)
    ticker = str(ticker)

    if ticker in _dividend_cache:
        return _dividend_cache[ticker]

    if not YFINANCE_AVAILABLE:
        _dividend_cache[ticker] = None
        return None

    try:
        ticker_clean = ticker.replace(".SA", "")
        ticker_yf = f"{ticker_clean}.SA"
        ativo = yf.Ticker(ticker_yf)
        calendar = ativo.calendar

        if calendar is not None and 'Ex-Dividend Date' in calendar:
            ex_date = pd.to_datetime(calendar['Ex-Dividend Date'])
            ex_date = ex_date.tz_localize(None)
            _dividend_cache[ticker] = ex_date
            return ex_date
    except Exception as e:
        print(f"Erro ao buscar dividendo para {ticker}: {e}")

    _dividend_cache[ticker] = None
    return None


def check_fundamental_filters(s1: str, s2: str, data: pd.DataFrame) -> Dict[str, Any]:
    """
    Verifica filtros fundamentais para evitar opera√ß√µes em momentos ruins.
    """
    filters = {
        "dividendos": {"proximos_5d": False, "data": None, "status": "‚úÖ"},
        "eventos_corporativos": {"tipo": None, "data": None, "status": "‚úÖ"},
        "baixa_liquidez": {"status": "‚úÖ"},
        "suspensao": {"status": "‚úÖ"}
    }

    today = pd.Timestamp.today().normalize()
    for ticker in [s1, s2]:
        ex_date = get_next_dividend_date(ticker)
        if ex_date is not None and today <= ex_date <= today + pd.Timedelta(days=5):
            filters["dividendos"]["proximos_5d"] = True
            filters["dividendos"]["data"] = ex_date
            filters["dividendos"]["status"] = "‚ö†Ô∏è"
            filters["eventos_corporativos"]["tipo"] = f"Dividendo {ticker}"
            filters["eventos_corporativos"]["status"] = "‚ö†Ô∏è"

    try:
        vol_s1 = data[s1].pct_change().std() * np.sqrt(252)
        vol_s2 = data[s2].pct_change().std() * np.sqrt(252)
        if vol_s1 > 0.6 or vol_s2 > 0.6:
            if filters["eventos_corporativos"]["status"] == "‚úÖ":
                filters["eventos_corporativos"]["tipo"] = "Alta volatilidade"
                filters["eventos_corporativos"]["status"] = "‚ö†Ô∏è"
    except:
        pass

    return filters


def calculate_rolling_beta(s1: pd.Series, s2: pd.Series, window: int = 60) -> pd.Series:
    """
    Calcula beta m√≥vel entre s1 ~ s2 com janela rolante.
    """
    if window < 2:
        raise ValueError("A janela deve ser >= 2")
    common_idx = s1.index.intersection(s2.index)
    if len(common_idx) < window:
        return pd.Series([], dtype=float)
    s1 = s1.loc[common_idx]
    s2 = s2.loc[common_idx]
    betas = []
    dates = []
    for i in range(window, len(s1)):
        y = s1.iloc[i - window:i]
        X = s2.iloc[i - window:i]
        X = sm.add_constant(X)
        try:
            model = sm.OLS(y, X).fit()
            beta = model.params.iloc[1]
        except:
            beta = np.nan
        betas.append(beta)
        dates.append(s1.index[i])
    return pd.Series(betas, index=dates)


def kalman_filter_hedge_ratio(s1: pd.Series, s2: pd.Series, delta: float = 1e-3,
                              initial_state_cov: float = 1.0) -> pd.Series:
    """
    Estima o hedge ratio din√¢mico usando Filtro de Kalman.
    
    Modelo: s1 = alpha + beta * s2 + epsilon
    Spread = s1 - beta * s2
    """
    try:
        common_idx = s1.index.intersection(s2.index)
        if len(common_idx) < 10:
            return pd.Series([], dtype=float)
        y = s1.loc[common_idx].values
        x = s2.loc[common_idx].values
        X = np.column_stack([np.ones(len(x)), x])
        R = 1.0
        delta = delta
        Qt = delta / (1 - delta) * np.eye(2)
        beta = np.zeros(2)
        P = np.eye(2) * initial_state_cov
        betas = []
        for t in range(len(y)):
            if t == 0:
                if len(y) >= 5:
                    beta_ols = np.linalg.pinv(X[:5].T @ X[:5]) @ X[:5].T @ y[:5]
                    beta = beta_ols
                    P = np.eye(2) * initial_state_cov
                else:
                    beta = np.array([0.0, 1.0])
            else:
                P = P + Qt
                pred = X[t] @ beta
                v = y[t] - pred
                F = X[t] @ P @ X[t] + R
                K = (P @ X[t]) / F
                beta = beta + K * v
                P = (np.eye(2) - np.outer(K, X[t])) @ P
            betas.append(beta[1])
        return pd.Series(betas, index=common_idx)
    except Exception as e:
        print(f"Kalman Filter erro: {e}")
        return pd.Series([], dtype=float)


def test_cointegration(s1: pd.Series, s2: pd.Series) -> Tuple[float, float, float]:
    """
    Teste de cointegra√ß√£o Engle-Granger com meia-vida.
    
    CONVEN√á√ÉO: 
    - Modelo: s1 ~ s2
    - Spread = s1 - beta * s2
    - Z-Score negativo ‚Üí s1 est√° barato ‚Üí Long s1, Short s2
    """
    try:
        s1_clean = s1.dropna()
        s2_clean = s2.reindex(s1_clean.index).dropna()
        common_idx = s1_clean.index.intersection(s2_clean.index)
        if len(common_idx) < 30:
            return (np.nan, np.nan, np.inf)
        y = s1_clean.loc[common_idx]
        X = s2_clean.loc[common_idx]
        X = sm.add_constant(X)
        model = sm.OLS(y, X).fit()
        residuals = model.resid
        adf_result = sm.tsa.stattools.adfuller(residuals, maxlag=1, autolag='AIC')
        pvalue = adf_result[1]
        spread_lag = residuals.shift(1)
        delta = residuals.diff().dropna()
        spread_lag = spread_lag.loc[delta.index]
        if len(spread_lag) < 2:
            hl = np.inf
        else:
            X_ar = sm.add_constant(spread_lag)
            model_ar = sm.OLS(delta, X_ar).fit()
            coef = model_ar.params.iloc[1]
            hl = -np.log(2) / coef if coef < 0 else np.inf
        beta_hedge = model.params.iloc[1]
        return (pvalue, beta_hedge, hl)
    except Exception as e:
        return (np.nan, np.nan, np.inf)


def calculate_zscore(spread: pd.Series, window: int = 20) -> pd.Series:
    """
    Calcula Z-Score m√≥vel com m√©dia e desvio rolantes.
    """
    if len(spread) < window:
        return (spread - spread.mean()) / spread.std() if spread.std() > 0 else spread * 0.0
    mean = spread.rolling(window=window).mean()
    std = spread.rolling(window=window).std()
    std = std.replace(0, np.nan)
    zscore = (spread - mean) / std
    return zscore


def analyze_residuals_diagnostics(residuals: pd.Series) -> Dict[str, Any]:
    """
    Realiza diagn√≥stico completo dos res√≠duos do modelo de cointegra√ß√£o.
    """
    if len(residuals) < 10:
        return {"error": "S√©rie muito curta"}
    diagnostics = {}
    try:
        from scipy.stats import shapiro
        _, p_shapiro = shapiro(residuals.dropna())
        diagnostics["normalidade"] = {
            "pvalor": p_shapiro,
            "normal": p_shapiro > 0.05,
            "status": "‚úÖ" if p_shapiro > 0.05 else "‚ö†Ô∏è"
        }
    except:
        diagnostics["normalidade"] = {"normal": False, "status": "‚ùå"}
    try:
        from statsmodels.stats.diagnostic import acorr_ljungbox
        lb_test = acorr_ljungbox(residuals.dropna(), lags=5, return_df=False)
        p_lb = np.min(lb_test[1])
        diagnostics["autocorrelacao"] = {
            "pvalor": p_lb,
            "sem_ac": p_lb > 0.05,
            "status": "‚úÖ" if p_lb > 0.05 else "‚ö†Ô∏è"
        }
    except:
        diagnostics["autocorrelacao"] = {"sem_ac": False, "status": "‚ùå"}
    try:
        from statsmodels.stats.diagnostic import het_breuschpagan
        X = sm.add_constant(np.arange(len(residuals)))
        bp_test = het_breuschpagan(residuals - residuals.mean(), X)
        p_bp = bp_test[1]
        diagnostics["heterocedasticidade"] = {
            "pvalor": p_bp,
            "homocedastico": p_bp > 0.05,
            "status": "‚úÖ" if p_bp > 0.05 else "‚ö†Ô∏è"
        }
    except:
        diagnostics["heterocedasticidade"] = {"homocedastico": False, "status": "‚ùå"}
    try:
        adf_stat, p_adf, _, _, _, _ = adfuller(residuals.dropna())
        diagnostics["estacionariedade"] = {
            "pvalor": p_adf,
            "estacionario": p_adf < 0.05,
            "status": "‚úÖ" if p_adf < 0.05 else "‚ö†Ô∏è"
        }
    except:
        diagnostics["estacionariedade"] = {"estacionario": False, "status": "‚ùå"}
    return diagnostics


# ========= NOVA FUN√á√ÉO 1: detect_structural_break =========
def detect_structural_break(residuals: pd.Series, threshold: float = 1.5) -> Dict[str, Any]:
    """
    Detecta rupturas estruturais nos res√≠duos usando CUSUM.
    """
    if len(residuals) < 20:
        return {"stable": True, "break_point": None, "status": "‚úÖ Est√°vel (poucos dados)"}
    
    # CUSUM simples
    std_resid = residuals.std()
    if std_resid == 0:
        return {"stable": False, "break_point": None, "status": "‚ùå Ruptura detectada"}
    
    cumsum = (residuals - residuals.mean()).cumsum() / std_resid
    upper_bound = threshold * np.sqrt(np.arange(len(cumsum)))
    lower_bound = -upper_bound
    
    # Verificar cruzamento
    if (cumsum > upper_bound).any() or (cumsum < lower_bound).any():
        idx = np.where((cumsum > upper_bound) | (cumsum < lower_bound))[0][0]
        date = residuals.index[idx]
        return {
            "stable": False,
            "break_point": date,
            "status": f"‚ùå Quebrado em {date.strftime('%d/%m')}"
        }
    
    return {"stable": True, "break_point": None, "status": "‚úÖ Est√°vel"}


# ========= NOVA FUN√á√ÉO 2: is_beta_stable =========
def is_beta_stable(beta_series: pd.Series, window: int = 30, max_std: float = 0.3) -> Dict[str, Any]:
    """
    Verifica se o beta estimado via Kalman est√° est√°vel.
    """
    if len(beta_series) < window:
        return {"stable": True, "std": 0.0, "status": "‚úÖ Est√°vel (poucos dados)"}
    
    recent_beta = beta_series.iloc[-window:]
    beta_std = recent_beta.std()
    
    stable = beta_std <= max_std
    status = "‚úÖ Est√°vel" if stable else f"‚ö†Ô∏è Inst√°vel ({beta_std:.3f})"
    
    return {"stable": stable, "std": float(beta_std), "status": status}


# ========= NOVA FUN√á√ÉO 3: is_market_volatility_low =========
def is_market_volatility_low(threshold: float = 35.0) -> Dict[str, Any]:
    """
    Verifica se o mercado est√° em regime de baixa volatilidade com base no IBOV.
    """
    if not YFINANCE_AVAILABLE:
        return {"calm": True, "vol_20d": 0.0, "status": "üü° Sem yfinance"}

    try:
        # Baixar dados do IBOV
        ibov_data = yf.download("^BVSP", period="3mo", interval="1d", progress=False)
        
        # ‚úÖ Verifica√ß√£o segura: checar se est√° vazio
        if ibov_data.empty:
            return {"calm": True, "vol_20d": 0.0, "status": "üü° Sem dados (IBOV)"}
        
        # ‚úÖ Verifica√ß√£o segura: coluna "Close" existe e n√£o est√° vazia
        if "Close" not in ibov_data or ibov_data["Close"].dropna().empty:
            return {"calm": True, "vol_20d": 0.0, "status": "üü° Sem dados de fechamento"}

        close = ibov_data["Close"].dropna()
        
        if len(close) < 20:
            return {"calm": True, "vol_20d": 0.0, "status": "üü° Poucos dados"}

        # ‚úÖ Retornos di√°rios
        returns = close.pct_change().dropna()
        
        if len(returns) < 20:
            return {"calm": True, "vol_20d": 0.0, "status": "üü° Poucos retornos"}

        # ‚úÖ Volatilidade anualizada dos √∫ltimos 20 dias
        vol_20d = returns.iloc[-20:].std() * np.sqrt(252) * 100  # em %

        # ‚úÖ Convers√£o segura para float
        vol_20d = float(vol_20d)
        
        # ‚úÖ Decis√£o clara
        calm = vol_20d <= threshold
        status = "üü¢ Calmo" if calm else f"‚ö†Ô∏è Vol√°til ({vol_20d:.1f}%)"

        return {
            "calm": bool(calm),
            "vol_20d": round(vol_20d, 1),
            "status": status
        }

    except Exception as e:
        print(f"Erro ao calcular volatilidade do mercado: {e}")
        return {"calm": True, "vol_20d": 0.0, "status": "üü° Erro ao checar"}
    
def diagnosticar_par(s1: pd.Series, s2: pd.Series, nome_s1: str, nome_s2: str):
    """
    Diagn√≥stico r√°pido para verificar se o z-score est√° coerente com os pre√ßos.
    """
    # Passo 1: calcular beta
    y = s1.dropna()
    x = s2.reindex(y.index).dropna()
    common_idx = y.index.intersection(x.index)
    y = y.loc[common_idx]
    x = x.loc[common_idx]

    if len(common_idx) < 20:
        print("‚ö†Ô∏è Poucos dados para diagn√≥stico")
        return

    X = sm.add_constant(x)
    model = sm.OLS(y, X).fit()
    beta = model.params.iloc[1]

    # Passo 2: calcular spread e z-score
    spread = y - beta * x
    zscore = (spread[-1] - spread.mean()) / spread.std()

    s1_atual = y.iloc[-1]
    s2_atual = x.iloc[-1]
    valor_justo_s1 = beta * s2_atual

    print(f"\nüîç DIAGN√ìSTICO DO PAR: {nome_s1} vs {nome_s2}")
    print(f"Beta: {beta:.3f}")
    print(f"{nome_s1} atual: R$ {s1_atual:.2f}")
    print(f"Valor justo (baseado em {nome_s2}): R$ {valor_justo_s1:.2f}")
    print(f"Z-Score atual: {zscore:.2f}")

    if zscore < -1.5:
        print(f"‚úÖ Sinal: Long {nome_s1}, Short {nome_s2}")
    elif zscore > 1.5:
        print(f"‚úÖ Sinal: Short {nome_s1}, Long {nome_s2}")
    else:
        print("üü° Sem sinal claro")